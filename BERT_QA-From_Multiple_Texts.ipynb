{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note if you are using google colab - please go to Runtime -> Change runtime type  and select GPU as Hardware accelerator. This will make notebook run faster.\n",
    "#github link: https://github.com/sanigam/BERT_QA_Medium\n",
    "\n",
    "\n",
    "#Install following libraries before first run. For subsequent runs, you may comment these\n",
    "# !pip install transformers\n",
    "# !pip install torch\n",
    "\n",
    "#Import libraries\n",
    "\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading BERT model already fine-tuned on SQuAD Question Answer Dataset. This 1.3 GB download and may take sometime\n",
    "# Note that we are using uncased model so all answers will be in lower case\n",
    "\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting bert tokenizer\n",
    "tokenizer_for_bert = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 6.13, 6.94, 'washington')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bert_answering_machine ( question, passage, max_len =  512):\n",
    "    ''' Function to provide answer from passage for question asked.\n",
    "        This function takes question as well as the passage \n",
    "        It retuns answer from the passage, along with start/end token index for the answer and start/end token scores\n",
    "        The scores can be used to rank answers if we are searching answers for same question in multiple passages\n",
    "        Value of max_len can not exceed 512. If length of question + passage + special tokens is bigger than max_len, function will truncate extra portion.\n",
    "        \n",
    "    '''\n",
    "  \n",
    "    #Tokenize input question and passage. Keeping maximum number of tokens as specified by max_len parameter. This will also add special tokens - [CLS] and [SEP]\n",
    "    input_ids = tokenizer_for_bert.encode ( question, passage,  max_length= max_len, truncation=True)  \n",
    "    \n",
    "    \n",
    "    #Getting number of tokens in 1st sentence (question) and 2nd sentence (passage)\n",
    "    cls_index = input_ids.index(102) #Getting index of first SEP token\n",
    "    len_question = cls_index + 1       # length of question (1st sentence)\n",
    "    len_answer = len(input_ids)- len_question  # length of answer (2nd sentence)\n",
    "    \n",
    "    \n",
    "    #BERT need Segment Ids to understand which tokens belong to sentence 1 and which to sentence 2\n",
    "    segment_ids =  [0]*len_question + [1]*(len_answer)  #Segment ids will be 0 for question and 1 for answer\n",
    "    \n",
    "    #Converting token ids to tokens\n",
    "    tokens = tokenizer_for_bert.convert_ids_to_tokens(input_ids) \n",
    "    \n",
    "    \n",
    "    # getting start and end scores for answer. Converting input arrays to torch tensors before passing to the model\n",
    "    start_token_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]) )[0]\n",
    "    end_token_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]) )[1]\n",
    "\n",
    "    #Converting scores tensors to numpy arrays so that we can use numpy functions\n",
    "    start_token_scores = start_token_scores.detach().numpy().flatten()\n",
    "    end_token_scores = end_token_scores.detach().numpy().flatten()\n",
    "    \n",
    "    #Picking start index and end index of answer based on start/end indices with highest scores\n",
    "    answer_start_index = np.argmax(start_token_scores)\n",
    "    answer_end_index = np.argmax(end_token_scores)\n",
    "\n",
    "    #Getting scores for start token and end token of the answer. Also rounding it to 2 decimal digits\n",
    "    start_token_score = np.round(start_token_scores[answer_start_index], 2)\n",
    "    end_token_score = np.round(end_token_scores[answer_end_index], 2)\n",
    "    \n",
    "   \n",
    "    #Combining subwords starting with ## so that we can see full words in output. Note tokenizer breaks words which are not in its vocab.\n",
    "    answer = tokens[answer_start_index] #Answer starts with start index, we got based on highest score\n",
    "    for i in range(answer_start_index + 1, answer_end_index + 1):\n",
    "        if tokens[i][0:2] == '##':  # Token for a splitted word starts with ##\n",
    "            answer += tokens[i][2:] # If token start with ## we remove ## and combine it with previous word so as to restore the unsplitted word\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]  # If token does not start with ## we just put a space in between while combining tokens\n",
    "            \n",
    "    # Few patterns indicating that BERT does not get answer from the passage for question asked\n",
    "    if ( answer_start_index == 0) or (start_token_score < 0 ) or  (answer == '[SEP]') or ( answer_end_index <  answer_start_index):\n",
    "        answer = \"Sorry!, I could not find  an answer in the passage.\"\n",
    "    \n",
    "    return ( answer_start_index, answer_end_index, start_token_score, end_token_score,  answer)\n",
    "\n",
    "\n",
    "#Testing function\n",
    "bert_answering_machine (\"Which state john's friend lives\", 'My name is John. I live in San Jose, California. Rob is my friend. He lives in Seattle, Washington')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to get answer from an array of passages\n",
    "def get_answer(q, p_array):\n",
    "    score_list = []\n",
    "    ans_list = []\n",
    "    j_list = []\n",
    "    for j in range (len(p_array)):  \n",
    "        #p = preprocess(p_array[j] )\n",
    "        p = p_array[j] \n",
    "\n",
    "        start, end , start_score, end_score,  ans = bert_answering_machine (q, p)\n",
    "        #print( '\\nText num:', j, 'Score:', start_score, end_score, '\\nBERT Answer:', ans)\n",
    "        \n",
    "        if (start != 0) and (start_score > 0.25)  and (ans != '[SEP]')  :\n",
    "            score_list.append(str(start_score) + ' and ' + str(end_score))\n",
    "            ans_list.append(ans)\n",
    "            j_list.append(j)\n",
    "        else:\n",
    "            text_num = None\n",
    "            token_scores = None\n",
    "            answer = \"No Answer From BERT\"\n",
    "\n",
    "            \n",
    "    if len(score_list) > 0 :\n",
    "        ind = np.argmax(score_list)\n",
    "        #print( 'Text number:', j_list[ind], ',  Token Scores:', score_list[ind], '\\nBERT Answer:', ans_list[ind])\n",
    "        text_num = j_list[ind]\n",
    "        token_scores = score_list[ind]\n",
    "        answer = ans_list[ind]\n",
    "    else:\n",
    "        text_num = None\n",
    "        token_scores = None\n",
    "        answer = \"No Answer From BERT\"\n",
    "    return text_num, token_scores, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage: 0 : I am a student , I study in UC Davis. I like to play Tennis\n",
      "\n",
      "Passage: 1 : John is a 10 year old boy. He is the son of Robert Smith.  Elizabeth Davis is Robert's wife. She teaches at UC Berkeley. Sophia Smith is Elizabeth's daughter. She studies at UC Davis\n",
      "\n",
      "Passage: 2 : My name is John. I live in San Jose, California. Rob is my friend. He lives in Seattle, Washington\n",
      "\n",
      "Answer: uc davis , Passage Index Where Answer Was Found: 1, Scores: 5.83 and 6.35\n"
     ]
    }
   ],
   "source": [
    "# passing 3 pagges and get_answer gets the  answer from best passege\n",
    "passages_array=[\"I am a student , I study in UC Davis. I like to play Tennis\",\n",
    "    \"John is a 10 year old boy. He is the son of Robert Smith.  Elizabeth Davis is Robert's wife. She teaches at UC Berkeley. Sophia Smith is Elizabeth's daughter. She studies at UC Davis\", \n",
    " \"My name is John. I live in San Jose, California. Rob is my friend. He lives in Seattle, Washington\" ]\n",
    "\n",
    "for i in range(len(passages_array)):\n",
    "    print (f'Passage: {i} : {passages_array[i]}\\n')\n",
    "question =\"Which college does John's sister attend\"  \n",
    "\n",
    "passage_num, scores, answer = get_answer(question, passages_array)\n",
    "\n",
    "print (f'Answer: {answer} , Passage Index Where Answer Was Found: {passage_num}, Scores: {scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
